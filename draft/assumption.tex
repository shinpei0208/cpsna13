\section{Assumption}
\label{sec:assumption}

We consider the system composed of a multicore CPU and commodity GPU.
They communicate with each other through the PCIe bus.
We use CUDA \cite{NVIDIA_CUDA} for GPU programming.
Its  development environment can be downloaded from NVIDIA's website
\cite{NVIDIA_NVCC}.
Input images are loaded from pre-captured JPEG files, since we focus on
a high computational cost of image processing.
A system coordination of computations and I/O devices is outside the
scope of this paper.

We follow the object detection method presented by Felzenszwalb
\textit{et. al.} \cite{Felzenszwalb10}, where objects are represented by
HOG features \cite{Dalal05} and the detectors is composed of a ``root''
filter plus a set of ``parts'' filters that allow visual appearance to
be modeled at multiple scales.
This is one of the most recognized approach to object detection.
See \cite{Felzenszwalb10} for the detail.

Object detection often requires a machine learning phase to construct
the object models.
We assume that this learning phase has already been done a priori and
the object models are stored in the system.
Particularly we restrict our attention to vehicle detection in this
paper, utilizing the vehicle models provided by prior work
\cite{Niknejad12}.
Although these models achieve a high detection rate, the computational
cost of scoring similarity of an imput image and the models using HOG
features is very expensive.
Specifically they include $2$ root filters and $12$ part filters, each
of which needs to be scored against $32$ resized images.
The scoring could be conducted for every $8 \times 8$ or $4 \times 4$
pixels independently.
In consequence, there are about $100$ billion computational blocks for
high-definition images.

